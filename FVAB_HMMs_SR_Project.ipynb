{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "FVAB_HMMs_SR_Project.ipynb",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "All import"
   ],
   "metadata": {
    "id": "_1FS1YYnxJoy",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import librosa as lb\n",
    "import librosa.display as display\n",
    "import librosa.effects as effects\n",
    "import numpy as np\n",
    "import csv as csv\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from IPython.display import Audio\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.impute import SimpleImputer\n",
    "from hmmlearn import hmm\n",
    "from hmmlearn import base\n",
    "from numpy import genfromtxt"
   ],
   "metadata": {
    "id": "mKs7zKLIw8eK",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alex\\PycharmProjects\\HMM_SR_project\\venv\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\Alex\\PycharmProjects\\HMM_SR_project\\venv\\lib\\site-packages\\numpy\\.libs\\libopenblas.EL2C6PLE4ZYW3ECEVIV3OXXGRN2NRFM2.gfortran-win_amd64.dll\n",
      "C:\\Users\\Alex\\PycharmProjects\\HMM_SR_project\\venv\\lib\\site-packages\\numpy\\.libs\\libopenblas.FB5AE2TYXYH2IJRDKGDGQ3XBKLKTF43H.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "defining pre_processing"
   ],
   "metadata": {
    "id": "mNa_-OsWxMjb",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "\n",
    "def pre_processing(path):\n",
    "  #load\n",
    "  audio, sr = lb.load(path = path, mono = True)\n",
    "\n",
    "  #pre-emp\n",
    "  pre_emp_audio = effects.preemphasis(audio, 0.97)\n",
    "\n",
    "\n",
    "  #removing silence in audio\n",
    "  clips = effects.split(pre_emp_audio, top_db=25)\n",
    "  silenced=[]\n",
    "  for c in clips:\n",
    "    data = audio[c[0]: c[1]]\n",
    "    silenced.extend(data)\n",
    "\n",
    "  silence = np.array(silenced)\n",
    "\n",
    "\n",
    "\n",
    "  return silence, sr\n",
    "\n",
    "EXAMPLE_PATH = \"/home/axel1143/Scrivania/Voxceleb_wav/wav/id10261/1suWlhhvRcs/00011.wav\"\n",
    "BASE_TRAINING_PATH=\"/home/axel1143/Scrivania/Voxceleb_wav/wav/\"\n",
    "BASE_PATH = \"C:\\\\Users\\\\Alex\\\\Desktop\\\\Voxceleb_mat\\\\\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**(example)** calculating mfcc, delta, delta2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "processed_audio, sr = pre_processing(EXAMPLE_PATH)\n",
    "print(len(processed_audio)/sr)\n",
    "mfcc = lb.feature.mfcc(y = processed_audio, sr = sr, n_mfcc = 13)\n",
    "mfcc_delta = lb.feature.delta(mfcc)\n",
    "mfcc_delta2 = lb.feature.delta(mfcc, order = 2)\n",
    "\n",
    "Audio(processed_audio, rate = sr)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**(example)** show mfcc, delta & delta2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows =3, sharex =True)\n",
    "\n",
    "img_mfcc = display.specshow(mfcc, ax=ax[0])\n",
    "\n",
    "img_delta = display.specshow(mfcc_delta, ax=ax[1])\n",
    "\n",
    "img_delta2 = display.specshow(mfcc_delta2, ax=ax[2])\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**(example)** single execution example"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "row_csv = []\n",
    "row_csv.append(\"id11\")\n",
    "row_csv.append(\"pathblablabla\")\n",
    "print(row_csv)\n",
    "for row in mfcc:\n",
    "  row_csv_2 = []\n",
    "  for value in row:\n",
    "    row_csv_2.append(value)\n",
    "  row_csv.append(row_csv_2)\n",
    "\n",
    "for row in mfcc_delta:\n",
    "  row_csv_2 = []\n",
    "  for value in row:\n",
    "    row_csv_2.append(value)\n",
    "  row_csv.append(row_csv_2)\n",
    "\n",
    "for row in mfcc_delta2:\n",
    "  row_csv_2 = []\n",
    "  for value in row:\n",
    "    row_csv_2.append(value)\n",
    "  row_csv.append(row_csv_2)\n",
    "\n",
    "header = [\"id\",\"path\",\n",
    "          \"mfcc1\",\"mfcc2\",\"mfcc3\",\"mfcc4\",\"mfcc5\",\"mfcc6\",\"mfcc7\",\"mfcc8\",\"mfcc9\",\"mfcc10\",\"mfcc11\",\"mfcc12\",\"mfcc13\",\n",
    "          \"delta1\",\"delta2\",\"delta3\",\"delta4\",\"delta5\",\"delta6\",\"delta7\",\"delta8\",\"delta9\",\"delta10\",\"delta11\",\"delta12\",\"delta13\",\n",
    "          \"delta2_1\",\"delta2_2\",\"delta2_3\",\"delta2_4\",\"delta2_5\",\"delta2_6\",\"delta2_7\",\"delta2_8\",\"delta2_9\",\"delta2_10\",\"delta2_11\",\"delta2_12\",\"delta2_13\"]\n",
    "\n",
    "with open(\"/content/drive/MyDrive/DATASET_VOXCELEB_1/file.csv\", \"w\", encoding=\"UTF-8\", newline=\"\") as cs:\n",
    "  writer = csv.writer(cs)\n",
    "  writer.writerow(header)\n",
    "  writer.writerow(row_csv)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**creating** csv\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "header = [\"id\",\"path\",\n",
    "          \"mfcc1\",\"mfcc2\",\"mfcc3\",\"mfcc4\",\"mfcc5\",\"mfcc6\",\"mfcc7\",\"mfcc8\",\"mfcc9\",\"mfcc10\",\"mfcc11\",\"mfcc12\",\"mfcc13\",\n",
    "          \"delta1\",\"delta2\",\"delta3\",\"delta4\",\"delta5\",\"delta6\",\"delta7\",\"delta8\",\"delta9\",\"delta10\",\"delta11\",\"delta12\",\"delta13\", \n",
    "          \"delta2_1\",\"delta2_2\",\"delta2_3\",\"delta2_4\",\"delta2_5\",\"delta2_6\",\"delta2_7\",\"delta2_8\",\"delta2_9\",\"delta2_10\",\"delta2_11\",\"delta2_12\",\"delta2_13\"]\n",
    "\n",
    "with open(BASE_PATH + \"id_mfcc_deltas_ridotto.csv\", \"w\", encoding=\"UTF-8\", newline=\"\") as writefile:\n",
    "  writer = csv.writer(writefile)\n",
    "  writer.writerow(header)\n",
    "  counter_speaker = 0\n",
    "  for dir in os.listdir(BASE_TRAINING_PATH):\n",
    "    if counter_speaker < 300:\n",
    "        counter_speaker+=1\n",
    "        count_audio = 0\n",
    "        for dir1 in os.listdir(BASE_TRAINING_PATH+dir):\n",
    "            if count_audio < 40:\n",
    "                for file in os.listdir(BASE_TRAINING_PATH+dir+\"/\"+dir1):\n",
    "                  if count_audio < 40:\n",
    "                      if not os.path.isdir(BASE_TRAINING_PATH+dir+\"/\"+dir1+\"/\"+file):\n",
    "                        count_audio +=1\n",
    "                        COMPLETE_PATH = BASE_TRAINING_PATH+dir+\"/\"+dir1+\"/\"+file\n",
    "                        processed_audio, sr = pre_processing(COMPLETE_PATH)\n",
    "\n",
    "                        #mfcc = get_mfcc_coefficient(processed_audio, rs) #my mfcc\n",
    "                        mfcc = lb.feature.mfcc(y = processed_audio, sr = sr, n_mfcc=13)\n",
    "                        mfcc_delta = lb.feature.delta(mfcc)\n",
    "                        mfcc_delta2 = lb.feature.delta(mfcc, order=2)\n",
    "\n",
    "                        row_csv = []\n",
    "                        row_csv.append(dir)\n",
    "                        row_csv.append(COMPLETE_PATH)\n",
    "\n",
    "\n",
    "                        for row in mfcc:\n",
    "                          row_csv_2 = []\n",
    "                          for value in row:\n",
    "                            row_csv_2.append(value)\n",
    "                          row_csv.append(row_csv_2)\n",
    "\n",
    "                        for row in mfcc_delta:\n",
    "                          row_csv_2 = []\n",
    "                          for value in row:\n",
    "                            row_csv_2.append(value)\n",
    "                          row_csv.append(row_csv_2)\n",
    "\n",
    "                        for row in mfcc_delta2:\n",
    "                          row_csv_2 = []\n",
    "                          for value in row:\n",
    "                            row_csv_2.append(value)\n",
    "                          row_csv.append(row_csv_2)\n",
    "\n",
    "                        writer.writerow(row_csv)\n",
    "\n",
    "        print(counter_speaker)\n",
    "    else:\n",
    "        continue"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "loading df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = pd.read_csv(BASE_PATH + \"id_mfcc_deltas_ridotto.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "mfcc dataset con esplosione coefficienti"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "features_mfcc = [\"mfcc1\", \"mfcc2\", \"mfcc3\", \"mfcc4\", \"mfcc5\", \"mfcc6\", \"mfcc7\", \"mfcc8\", \"mfcc9\", \"mfcc10\", \"mfcc11\",\n",
    "            \"mfcc12\", \"mfcc13\"]\n",
    "\n",
    "labels = df.loc[:, [\"id\"]].values #labael dataset\n",
    "features_mfcc_values = df.loc[:, features_mfcc].values #mfcc dataset\n",
    "\n",
    "del df\n",
    "\n",
    "total = features_mfcc_values.shape[0] * features_mfcc_values.shape[1]\n",
    "counter = 0\n",
    "correct_dataset_mfcc = []\n",
    "header = []\n",
    "\n",
    "with open(BASE_PATH + \"id_mfcc_solo_ridotto.csv\", \"w\", encoding=\"UTF-8\", newline=\"\") as writefile:\n",
    "    writer = csv.writer(writefile)\n",
    "    for i in range(features_mfcc_values.shape[0]): #\n",
    "        row_dataset = []\n",
    "        #row_dataset.append(labels[i])\n",
    "        for j in range(features_mfcc_values.shape[1]):\n",
    "            features_mfcc_values[i][j] = features_mfcc_values[i][j].split()\n",
    "            for k in range(len(features_mfcc_values[i][j])):\n",
    "                features_mfcc_values[i][j][k] = features_mfcc_values[i][j][k].replace(\"[\", \"\")\n",
    "                features_mfcc_values[i][j][k] = features_mfcc_values[i][j][k].replace(\"]\", \"\")\n",
    "                features_mfcc_values[i][j][k] = features_mfcc_values[i][j][k].replace(\",\", \"\")\n",
    "            for ele in features_mfcc_values[i][j]:\n",
    "                if ele == \"\":\n",
    "                    features_mfcc_values[i][j].remove(ele)\n",
    "            for k in range(len(features_mfcc_values[i][j])):\n",
    "                features_mfcc_values[i][j][k] = float(features_mfcc_values[i][j][k])\n",
    "                row_dataset.append(features_mfcc_values[i][j][k])\n",
    "        correct_dataset_mfcc.append(row_dataset)\n",
    "        counter += 1\n",
    "        print(counter, \"/\", features_mfcc_values.shape[0])\n",
    "\n",
    "    len_max = 0\n",
    "    for row in correct_dataset_mfcc:\n",
    "        if len(row) > len_max:\n",
    "            len_max = len(row)\n",
    "\n",
    "    for i in range(len_max):\n",
    "        header.append(\"mfcc_\" + str(i))\n",
    "\n",
    "    print(len_max)\n",
    "\n",
    "    writer.writerow(header)\n",
    "    writer.writerows(correct_dataset_mfcc)\n",
    "\n",
    "del correct_dataset_mfcc\n",
    "del features_mfcc_values"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "mfcc riempiti con media"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded csv\n",
      "dataframe completed\n",
      "          mfcc_0     mfcc_1     mfcc_2     mfcc_3      mfcc_4     mfcc_5  \\\n",
      "0     -257.97195 -230.95300 -224.49272 -223.02423 -217.985810 -200.15079   \n",
      "1     -222.82971 -177.45796 -144.76396 -131.10254 -119.256035 -110.73129   \n",
      "2     -256.69763 -230.69241 -231.23729 -239.27986 -243.750370 -222.89789   \n",
      "3     -447.66022 -364.88420 -340.55670 -351.75708 -369.286770 -372.16720   \n",
      "4     -345.65176 -337.67172 -342.77338 -333.55093 -330.994960 -328.49884   \n",
      "...          ...        ...        ...        ...         ...        ...   \n",
      "11995 -381.94952 -349.82830 -346.78622 -358.00244 -365.792800 -367.26624   \n",
      "11996 -390.75390 -352.10690 -340.24660 -338.99420 -344.979800 -371.16300   \n",
      "11997 -498.38303 -440.63090 -369.90802 -364.75470 -396.901600 -431.09670   \n",
      "11998 -402.48422 -265.44583 -222.53365 -252.51994 -354.065500 -435.74020   \n",
      "11999 -569.40330 -432.81006 -402.12128 -427.02840 -450.925200 -403.64014   \n",
      "\n",
      "          mfcc_6     mfcc_7     mfcc_8     mfcc_9  ...  mfcc_29942  \\\n",
      "0     -188.88948 -192.92793 -198.64996 -205.36676  ...         NaN   \n",
      "1     -127.48655 -147.36304 -173.15262 -206.36018  ...         NaN   \n",
      "2     -154.01764 -105.64315  -93.18479 -100.65769  ...         NaN   \n",
      "3     -368.38434 -366.10820 -369.49774 -371.48330  ...         NaN   \n",
      "4     -328.54266 -344.72568 -359.26860 -376.84415  ...         NaN   \n",
      "...          ...        ...        ...        ...  ...         ...   \n",
      "11995 -383.24716 -407.05880 -401.32803 -403.24730  ...         NaN   \n",
      "11996 -387.86462 -349.09890 -298.46173 -279.32150  ...         NaN   \n",
      "11997 -458.27768 -415.12700 -367.14423 -356.79040  ...         NaN   \n",
      "11998 -463.90630 -434.85425 -338.91168 -293.68906  ...         NaN   \n",
      "11999 -360.11590 -380.71494 -443.04926 -498.42990  ...         NaN   \n",
      "\n",
      "       mfcc_29943  mfcc_29944  mfcc_29945  mfcc_29946  mfcc_29947  mfcc_29948  \\\n",
      "0             NaN         NaN         NaN         NaN         NaN         NaN   \n",
      "1             NaN         NaN         NaN         NaN         NaN         NaN   \n",
      "2             NaN         NaN         NaN         NaN         NaN         NaN   \n",
      "3             NaN         NaN         NaN         NaN         NaN         NaN   \n",
      "4             NaN         NaN         NaN         NaN         NaN         NaN   \n",
      "...           ...         ...         ...         ...         ...         ...   \n",
      "11995         NaN         NaN         NaN         NaN         NaN         NaN   \n",
      "11996         NaN         NaN         NaN         NaN         NaN         NaN   \n",
      "11997         NaN         NaN         NaN         NaN         NaN         NaN   \n",
      "11998         NaN         NaN         NaN         NaN         NaN         NaN   \n",
      "11999         NaN         NaN         NaN         NaN         NaN         NaN   \n",
      "\n",
      "       mfcc_29949  mfcc_29950  mfcc_29951  \n",
      "0             NaN         NaN         NaN  \n",
      "1             NaN         NaN         NaN  \n",
      "2             NaN         NaN         NaN  \n",
      "3             NaN         NaN         NaN  \n",
      "4             NaN         NaN         NaN  \n",
      "...           ...         ...         ...  \n",
      "11995         NaN         NaN         NaN  \n",
      "11996         NaN         NaN         NaN  \n",
      "11997         NaN         NaN         NaN  \n",
      "11998         NaN         NaN         NaN  \n",
      "11999         NaN         NaN         NaN  \n",
      "\n",
      "[12000 rows x 29952 columns]\n"
     ]
    }
   ],
   "source": [
    "mfcc = pd.read_csv(BASE_PATH + \"id_mfcc_solo_ridotto.csv\")\n",
    "print(\"loaded csv\")\n",
    "df_mfcc = pd.DataFrame(mfcc)\n",
    "print(\"dataframe completed\")\n",
    "\n",
    "\n",
    "print(mfcc)\n",
    "#imp_mean = SimpleImputer(missing_values=np.nan,  strategy=\"mean\")\n",
    "#filled = imp_mean.fit_transform(df_mfcc)\n",
    "\n",
    "#completed = pd.DataFrame(filled)\n",
    "#completed.to_csv(BASE_PATH+ 'mfcc_filled_mean.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "(ricontrollare)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "delta = pd.read_csv(BASE_PATH + \"id_delta_solo_ridotto.csv\")\n",
    "print(\"loaded csv\")\n",
    "df_delta = pd.DataFrame(delta)\n",
    "print(\"dataframe completed\")\n",
    "del delta\n",
    "\n",
    "imp_mean = SimpleImputer(missing_values=np.nan,  strategy=\"mean\")\n",
    "filled = imp_mean.fit_transform(df_delta)\n",
    "del df_delta\n",
    "print(\"imputer complete\")\n",
    "df_delta_scalar = StandardScaler().fit_transform(filled)\n",
    "\n",
    "del filled\n",
    "print(\"scalar complete\")\n",
    "complete = pd.DataFrame(df_delta_scalar)\n",
    "print(complete.head())\n",
    "del df_delta_scalar\n",
    "\n",
    "pca = PCA(n_components=10000) #38% of total\n",
    "pca_c = pca.fit_transform(complete)\n",
    "pca_df = pd.DataFrame(pca_c)\n",
    "print(\"pca complete, saving...\")\n",
    "pca_df.to_csv(BASE_PATH + 'pca_delta.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "(ricontrollare)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "delta2 = pd.read_csv(BASE_PATH + \"id_delta2_solo_ridotto.csv\")\n",
    "print(\"loaded csv\")\n",
    "df_delta2 = pd.DataFrame(delta2)\n",
    "print(\"dataframe completed\")\n",
    "del delta2\n",
    "\n",
    "imp_mean = SimpleImputer(missing_values=np.nan,  strategy=\"mean\")\n",
    "filled = imp_mean.fit_transform(df_delta2)\n",
    "del df_delta2\n",
    "print(\"imputer complete\")\n",
    "df_delta2_scalar = StandardScaler().fit_transform(filled)\n",
    "\n",
    "del filled\n",
    "print(\"scalar complete\")\n",
    "complete = pd.DataFrame(df_delta2_scalar)\n",
    "print(complete.head())\n",
    "del df_delta2_scalar\n",
    "\n",
    "pca = PCA(n_components=10000) #38% of total\n",
    "pca_c = pca.fit_transform(complete)\n",
    "pca_df = pd.DataFrame(pca_c)\n",
    "print(\"pca complete, saving...\")\n",
    "pca_df.to_csv(BASE_PATH + 'pca_delta2.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "vector quantization con kmeans"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "Y = np.array(pd.read_csv(BASE_PATH + \"mfcc_filled_mean.csv\"))\n",
    "Y = np.float32(Y)\n",
    "X = Y.reshape((-1, 1))\n",
    "\n",
    "kmeans = KMeans(n_clusters=50)\n",
    "kmeans.fit(X)\n",
    "\n",
    "mfcc_shape = X.shape\n",
    "np.random.seed(0)\n",
    "\n",
    "values = kmeans.cluster_centers_.squeeze()\n",
    "labels = kmeans.labels_\n",
    "\n",
    "matrix = []\n",
    "row = []\n",
    "v_index = 0\n",
    "for i in range(Y.shape[0]):\n",
    "    for j in range(Y.shape[1]):\n",
    "        row.append(values[labels[v_index + j]])\n",
    "    row = np.array(row)\n",
    "    v_index += Y.shape[1]\n",
    "    matrix.append(row)\n",
    "    row = []\n",
    "\n",
    "matrix = np.array(matrix)\n",
    "#mfcc_compressed = np.choose(lables, values)\n",
    "#mfcc_compressed.shape = mfcc_shape\n",
    "\n",
    "mfcc_vc = pd.DataFrame(matrix)\n",
    "mfcc_vc.to_csv(BASE_PATH +\"mfcc_quantized_50.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "converting kmeans to observation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           0          1          2          3          4          5      \\\n",
      "0     -250.36732 -229.98515 -229.98515 -229.98515 -208.57301 -208.57301   \n",
      "1     -229.98515 -185.25190 -158.99754 -128.83252 -128.83252 -101.17104   \n",
      "2     -250.36732 -229.98515 -229.98515 -229.98515 -250.36732 -229.98515   \n",
      "3     -461.55180 -375.24582 -330.73904 -352.28055 -375.24582 -375.24582   \n",
      "4     -352.28055 -330.73904 -352.28055 -330.73904 -330.73904 -330.73904   \n",
      "...          ...        ...        ...        ...        ...        ...   \n",
      "11995 -375.24582 -352.28055 -352.28055 -352.28055 -375.24582 -375.24582   \n",
      "11996 -400.21760 -352.28055 -330.73904 -330.73904 -352.28055 -375.24582   \n",
      "11997 -503.72710 -428.37012 -375.24582 -375.24582 -400.21760 -428.37012   \n",
      "11998 -400.21760 -270.26590 -229.98515 -250.36732 -352.28055 -428.37012   \n",
      "11999 -568.03955 -428.37012 -400.21760 -428.37012 -461.55180 -400.21760   \n",
      "\n",
      "           6          7          8          9      ...      29942      29943  \\\n",
      "0     -185.25190 -185.25190 -208.57301 -208.57301  ... -20.597816 -25.789259   \n",
      "1     -128.83252 -158.99754 -185.25190 -208.57301  ... -20.597816 -25.789259   \n",
      "2     -158.99754 -101.17104 -101.17104 -101.17104  ... -20.597816 -25.789259   \n",
      "3     -375.24582 -375.24582 -375.24582 -375.24582  ... -20.597816 -25.789259   \n",
      "4     -330.73904 -352.28055 -352.28055 -375.24582  ... -20.597816 -25.789259   \n",
      "...          ...        ...        ...        ...  ...        ...        ...   \n",
      "11995 -375.24582 -400.21760 -400.21760 -400.21760  ... -20.597816 -25.789259   \n",
      "11996 -400.21760 -352.28055 -290.09210 -270.26590  ... -20.597816 -25.789259   \n",
      "11997 -461.55180 -428.37012 -375.24582 -352.28055  ... -20.597816 -25.789259   \n",
      "11998 -461.55180 -428.37012 -330.73904 -290.09210  ... -20.597816 -25.789259   \n",
      "11999 -352.28055 -375.24582 -428.37012 -503.72710  ... -20.597816 -25.789259   \n",
      "\n",
      "           29944      29945      29946      29947     29948     29949  \\\n",
      "0     -25.789259 -20.597816 -16.054625 -12.313332 -6.614696 -9.112648   \n",
      "1     -25.789259 -20.597816 -16.054625 -12.313332 -6.614696 -9.112648   \n",
      "2     -25.789259 -20.597816 -16.054625 -12.313332 -6.614696 -9.112648   \n",
      "3     -25.789259 -20.597816 -16.054625 -12.313332 -6.614696 -9.112648   \n",
      "4     -25.789259 -20.597816 -16.054625 -12.313332 -6.614696 -9.112648   \n",
      "...          ...        ...        ...        ...       ...       ...   \n",
      "11995 -25.789259 -20.597816 -16.054625 -12.313332 -6.614696 -9.112648   \n",
      "11996 -25.789259 -20.597816 -16.054625 -12.313332 -6.614696 -9.112648   \n",
      "11997 -25.789259 -20.597816 -16.054625 -12.313332 -6.614696 -9.112648   \n",
      "11998 -25.789259 -20.597816 -16.054625 -12.313332 -6.614696 -9.112648   \n",
      "11999 -25.789259 -20.597816 -16.054625 -12.313332 -6.614696 -9.112648   \n",
      "\n",
      "          29950     29951  \n",
      "0     -6.614696 -6.614696  \n",
      "1     -6.614696 -6.614696  \n",
      "2     -6.614696 -6.614696  \n",
      "3     -6.614696 -6.614696  \n",
      "4     -6.614696 -6.614696  \n",
      "...         ...       ...  \n",
      "11995 -6.614696 -6.614696  \n",
      "11996 -6.614696 -6.614696  \n",
      "11997 -6.614696 -6.614696  \n",
      "11998 -6.614696 -6.614696  \n",
      "11999 -6.614696 -6.614696  \n",
      "\n",
      "[12000 rows x 29952 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "observations = pd.read_csv(BASE_PATH + \"kmeans\\\\mfcc_quantized_50.csv\")\n",
    "\n",
    "observations = np.array(observations)\n",
    "observations = np.delete(observations, 0, axis=1)\n",
    "observations = pd.DataFrame(observations)\n",
    "\n",
    "def assign(x):\n",
    "    labels = [-250.36732, -229.98515, -208.57301, -185.2519, -158.99754, -128.83252, -101.17104, -64.64996, -80.61081, -270.2659, 110.14879, 128.67549, 90.649704, 72.6692, 145.3344, 160.91609, 43.268597, 31.461279, 57.029556, -32.565426, -41.14398, -51.852875, -20.597816, 0.048805714, -9.112648, -12.313332, -6.6146965, -25.789259, -16.054625, -3.766737, 21.845823, 14.8497505, 9.700958, 5.6986403, 2.5267844, -4.8695154, -2.0526307, 176.55214, -461.5518, -375.24582, -330.73904, -352.28055, -310.14545, -400.2176, -428.37012, -290.0921, -503.7271, 193.83801, 216.51389, -568.03955]\n",
    "    return labels.index(x)\n",
    "\n",
    "#obs1 = observations[0:35]\n",
    "observations1 = np.array(observations)\n",
    "print(observations1)\n",
    "counter_row = 0\n",
    "obs_labeled = []\n",
    "for row in observations1:\n",
    "    obs_labeled.append(np.array([assign(xi) for xi in row]))\n",
    "    counter_row+=1\n",
    "    print(counter_row)\n",
    "\n",
    "obs_np = np.array(obs_labeled)\n",
    "\n",
    "pd.DataFrame(obs_np).to_csv(BASE_PATH+\"hmm\\\\obs_labeled\", index=None, header=None)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(288000, 1248)\n"
     ]
    }
   ],
   "source": [
    "###\n",
    "observations = np.array(observations)\n",
    "observations_reshaped = []\n",
    "for row in observations:\n",
    "    reshaped = row.reshape(24, 1248)\n",
    "    for row_r in reshaped:\n",
    "        observations_reshaped.append(row_r)\n",
    "\n",
    "observations_reshaped = np.array(observations_reshaped)\n",
    "print(observations_reshaped.shape)\n",
    "###"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "test set & train set"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1499\n",
      "10500\n"
     ]
    }
   ],
   "source": [
    "observations = np.array(pd.read_csv(BASE_PATH + \"hmm\\\\obs_labeled.csv\"))\n",
    "index = 0\n",
    "train_set = []\n",
    "test_set = []\n",
    "for row in observations:\n",
    "    if 0 <= index <= 34:\n",
    "        train_set.append(row)\n",
    "        index+=1\n",
    "    elif index <= 38:\n",
    "        test_set.append(row)\n",
    "        index+=1\n",
    "    elif index == 39:\n",
    "        test_set.append(row)\n",
    "        index = 0\n",
    "\n",
    "print(len(test_set))\n",
    "print(len(train_set))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3  4  4 ... 24 26 26]\n",
      " [ 5  5  4 ... 24 26 26]\n",
      " [ 4  4  5 ... 24 26 26]\n",
      " ...\n",
      " [46 44 39 ... 24 26 26]\n",
      " [43  9  1 ... 24 26 26]\n",
      " [49 44 43 ... 24 26 26]]\n",
      "[[ 1  3  4 ... 24 26 26]\n",
      " [ 0  1  1 ... 24 26 26]\n",
      " [38 39 40 ... 24 26 26]\n",
      " ...\n",
      " [43 39 42 ... 24 26 26]\n",
      " [ 9  2  2 ... 24 26 26]\n",
      " [39 41 41 ... 24 26 26]]\n"
     ]
    }
   ],
   "source": [
    "test_set = np.array(test_set)\n",
    "train_set = np.array(train_set)\n",
    "\n",
    "print(test_set)\n",
    "print(train_set)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ]
}