{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "FVAB_HMMs_SR_Project.ipynb",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "All import"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import librosa as lb\n",
    "import librosa.display as display\n",
    "import librosa.effects as effects\n",
    "import numpy as np\n",
    "import csv as csv\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from IPython.display import Audio\n",
    "\n",
    "from hmmlearn import hmm\n",
    "\n",
    "import sys"
   ],
   "metadata": {
    "id": "mKs7zKLIw8eK",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "defining pre_processing"
   ],
   "metadata": {
    "id": "mNa_-OsWxMjb",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "\n",
    "def pre_processing(path):\n",
    "  #load\n",
    "  audio, sr = lb.load(path = path, mono = True)\n",
    "\n",
    "  #pre-emp\n",
    "  pre_emp_audio = effects.preemphasis(audio, 0.97)\n",
    "\n",
    "\n",
    "  #removing silence in audio\n",
    "  clips = effects.split(pre_emp_audio, top_db=25)\n",
    "  silenced=[]\n",
    "  for c in clips:\n",
    "    data = audio[c[0]: c[1]]\n",
    "    silenced.extend(data)\n",
    "\n",
    "  silence = np.array(silenced)\n",
    "\n",
    "\n",
    "\n",
    "  return silence, sr\n",
    "\n",
    "EXAMPLE_PATH = \"/home/axel1143/Scrivania/Voxceleb_wav/wav/id10261/1suWlhhvRcs/00011.wav\"\n",
    "BASE_TRAINING_PATH=\"/home/axel1143/Scrivania/Voxceleb_wav/wav/\"\n",
    "BASE_PATH = \"C:\\\\Users\\\\alexp\\\\Desktop\\\\Voxceleb_mat\\\\\"\n",
    "#BASE_PATH = \"/home/alex/Scrivania/Voxceleb_mat/\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**(example)** calculating mfcc, delta, delta2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "processed_audio, sr = pre_processing(EXAMPLE_PATH)\n",
    "print(len(processed_audio)/sr)\n",
    "mfcc = lb.feature.mfcc(y = processed_audio, sr = sr, n_mfcc = 13)\n",
    "mfcc_delta = lb.feature.delta(mfcc)\n",
    "mfcc_delta2 = lb.feature.delta(mfcc, order = 2)\n",
    "\n",
    "Audio(processed_audio, rate = sr)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**(example)** show mfcc, delta & delta2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows =3, sharex =True)\n",
    "\n",
    "img_mfcc = display.specshow(mfcc, ax=ax[0])\n",
    "\n",
    "img_delta = display.specshow(mfcc_delta, ax=ax[1])\n",
    "\n",
    "img_delta2 = display.specshow(mfcc_delta2, ax=ax[2])\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**(example)** single execution example"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "row_csv = []\n",
    "row_csv.append(\"id11\")\n",
    "row_csv.append(\"pathblablabla\")\n",
    "print(row_csv)\n",
    "for row in mfcc:\n",
    "  row_csv_2 = []\n",
    "  for value in row:\n",
    "    row_csv_2.append(value)\n",
    "  row_csv.append(row_csv_2)\n",
    "\n",
    "for row in mfcc_delta:\n",
    "  row_csv_2 = []\n",
    "  for value in row:\n",
    "    row_csv_2.append(value)\n",
    "  row_csv.append(row_csv_2)\n",
    "\n",
    "for row in mfcc_delta2:\n",
    "  row_csv_2 = []\n",
    "  for value in row:\n",
    "    row_csv_2.append(value)\n",
    "  row_csv.append(row_csv_2)\n",
    "\n",
    "header = [\"id\",\"path\",\n",
    "          \"mfcc1\",\"mfcc2\",\"mfcc3\",\"mfcc4\",\"mfcc5\",\"mfcc6\",\"mfcc7\",\"mfcc8\",\"mfcc9\",\"mfcc10\",\"mfcc11\",\"mfcc12\",\"mfcc13\",\n",
    "          \"delta1\",\"delta2\",\"delta3\",\"delta4\",\"delta5\",\"delta6\",\"delta7\",\"delta8\",\"delta9\",\"delta10\",\"delta11\",\"delta12\",\"delta13\",\n",
    "          \"delta2_1\",\"delta2_2\",\"delta2_3\",\"delta2_4\",\"delta2_5\",\"delta2_6\",\"delta2_7\",\"delta2_8\",\"delta2_9\",\"delta2_10\",\"delta2_11\",\"delta2_12\",\"delta2_13\"]\n",
    "\n",
    "with open(\"/content/drive/MyDrive/DATASET_VOXCELEB_1/file.csv\", \"w\", encoding=\"UTF-8\", newline=\"\") as cs:\n",
    "  writer = csv.writer(cs)\n",
    "  writer.writerow(header)\n",
    "  writer.writerow(row_csv)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**creating** csv\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "header = [\"id\",\"path\",\n",
    "          \"mfcc1\",\"mfcc2\",\"mfcc3\",\"mfcc4\",\"mfcc5\",\"mfcc6\",\"mfcc7\",\"mfcc8\",\"mfcc9\",\"mfcc10\",\"mfcc11\",\"mfcc12\",\"mfcc13\",\n",
    "          \"delta1\",\"delta2\",\"delta3\",\"delta4\",\"delta5\",\"delta6\",\"delta7\",\"delta8\",\"delta9\",\"delta10\",\"delta11\",\"delta12\",\"delta13\", \n",
    "          \"delta2_1\",\"delta2_2\",\"delta2_3\",\"delta2_4\",\"delta2_5\",\"delta2_6\",\"delta2_7\",\"delta2_8\",\"delta2_9\",\"delta2_10\",\"delta2_11\",\"delta2_12\",\"delta2_13\"]\n",
    "\n",
    "with open(BASE_PATH + \"id_mfcc_deltas_ridotto.csv\", \"w\", encoding=\"UTF-8\", newline=\"\") as writefile:\n",
    "  writer = csv.writer(writefile)\n",
    "  writer.writerow(header)\n",
    "  counter_speaker = 0\n",
    "  for dir in os.listdir(BASE_TRAINING_PATH):\n",
    "    if counter_speaker < 300:\n",
    "        counter_speaker+=1\n",
    "        count_audio = 0\n",
    "        for dir1 in os.listdir(BASE_TRAINING_PATH+dir):\n",
    "            if count_audio < 40:\n",
    "                for file in os.listdir(BASE_TRAINING_PATH+dir+\"/\"+dir1):\n",
    "                  if count_audio < 40:\n",
    "                      if not os.path.isdir(BASE_TRAINING_PATH+dir+\"/\"+dir1+\"/\"+file):\n",
    "                        count_audio +=1\n",
    "                        COMPLETE_PATH = BASE_TRAINING_PATH+dir+\"/\"+dir1+\"/\"+file\n",
    "                        processed_audio, sr = pre_processing(COMPLETE_PATH)\n",
    "\n",
    "                        #mfcc = get_mfcc_coefficient(processed_audio, rs) #my mfcc\n",
    "                        mfcc = lb.feature.mfcc(y = processed_audio, sr = sr, n_mfcc=13)\n",
    "                        mfcc_delta = lb.feature.delta(mfcc)\n",
    "                        mfcc_delta2 = lb.feature.delta(mfcc, order=2)\n",
    "\n",
    "                        row_csv = []\n",
    "                        row_csv.append(dir)\n",
    "                        row_csv.append(COMPLETE_PATH)\n",
    "\n",
    "\n",
    "                        for row in mfcc:\n",
    "                          row_csv_2 = []\n",
    "                          for value in row:\n",
    "                            row_csv_2.append(value)\n",
    "                          row_csv.append(row_csv_2)\n",
    "\n",
    "                        for row in mfcc_delta:\n",
    "                          row_csv_2 = []\n",
    "                          for value in row:\n",
    "                            row_csv_2.append(value)\n",
    "                          row_csv.append(row_csv_2)\n",
    "\n",
    "                        for row in mfcc_delta2:\n",
    "                          row_csv_2 = []\n",
    "                          for value in row:\n",
    "                            row_csv_2.append(value)\n",
    "                          row_csv.append(row_csv_2)\n",
    "\n",
    "                        writer.writerow(row_csv)\n",
    "\n",
    "        print(counter_speaker)\n",
    "    else:\n",
    "        continue"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "loading df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = pd.read_csv(BASE_PATH + \"id_mfcc_deltas_ridotto.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "mfcc dataset con esplosione coefficienti"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "features_mfcc = [\"mfcc1\", \"mfcc2\", \"mfcc3\", \"mfcc4\", \"mfcc5\", \"mfcc6\", \"mfcc7\", \"mfcc8\", \"mfcc9\", \"mfcc10\", \"mfcc11\",\n",
    "            \"mfcc12\", \"mfcc13\"]\n",
    "\n",
    "labels = df.loc[:, [\"id\"]].values #labael dataset\n",
    "features_mfcc_values = df.loc[:, features_mfcc].values #mfcc dataset\n",
    "\n",
    "del df\n",
    "\n",
    "total = features_mfcc_values.shape[0] * features_mfcc_values.shape[1]\n",
    "counter = 0\n",
    "correct_dataset_mfcc = []\n",
    "header = []\n",
    "\n",
    "with open(BASE_PATH + \"id_mfcc_solo_ridotto.csv\", \"w\", encoding=\"UTF-8\", newline=\"\") as writefile:\n",
    "    writer = csv.writer(writefile)\n",
    "    for i in range(features_mfcc_values.shape[0]): #\n",
    "        row_dataset = []\n",
    "        #row_dataset.append(labels[i])\n",
    "        for j in range(features_mfcc_values.shape[1]):\n",
    "            features_mfcc_values[i][j] = features_mfcc_values[i][j].split()\n",
    "            for k in range(len(features_mfcc_values[i][j])):\n",
    "                features_mfcc_values[i][j][k] = features_mfcc_values[i][j][k].replace(\"[\", \"\")\n",
    "                features_mfcc_values[i][j][k] = features_mfcc_values[i][j][k].replace(\"]\", \"\")\n",
    "                features_mfcc_values[i][j][k] = features_mfcc_values[i][j][k].replace(\",\", \"\")\n",
    "            for ele in features_mfcc_values[i][j]:\n",
    "                if ele == \"\":\n",
    "                    features_mfcc_values[i][j].remove(ele)\n",
    "            for k in range(len(features_mfcc_values[i][j])):\n",
    "                features_mfcc_values[i][j][k] = float(features_mfcc_values[i][j][k])\n",
    "                row_dataset.append(features_mfcc_values[i][j][k])\n",
    "        correct_dataset_mfcc.append(row_dataset)\n",
    "        counter += 1\n",
    "        print(counter, \"/\", features_mfcc_values.shape[0])\n",
    "\n",
    "    len_max = 0\n",
    "    for row in correct_dataset_mfcc:\n",
    "        if len(row) > len_max:\n",
    "            len_max = len(row)\n",
    "\n",
    "    for i in range(len_max):\n",
    "        header.append(\"mfcc_\" + str(i))\n",
    "\n",
    "    print(len_max)\n",
    "\n",
    "    writer.writerow(header)\n",
    "    writer.writerows(correct_dataset_mfcc)\n",
    "\n",
    "del correct_dataset_mfcc\n",
    "del features_mfcc_values"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "mfcc riempiti in maniera circolare"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded csv\n",
      "dataframe completed\n",
      "          mfcc_0     mfcc_1     mfcc_2     mfcc_3      mfcc_4     mfcc_5  \\\n",
      "0     -257.97195 -230.95300 -224.49272 -223.02423 -217.985810 -200.15079   \n",
      "1     -222.82971 -177.45796 -144.76396 -131.10254 -119.256035 -110.73129   \n",
      "2     -256.69763 -230.69241 -231.23729 -239.27986 -243.750370 -222.89789   \n",
      "3     -447.66022 -364.88420 -340.55670 -351.75708 -369.286770 -372.16720   \n",
      "4     -345.65176 -337.67172 -342.77338 -333.55093 -330.994960 -328.49884   \n",
      "...          ...        ...        ...        ...         ...        ...   \n",
      "11995 -381.94952 -349.82830 -346.78622 -358.00244 -365.792800 -367.26624   \n",
      "11996 -390.75390 -352.10690 -340.24660 -338.99420 -344.979800 -371.16300   \n",
      "11997 -498.38303 -440.63090 -369.90802 -364.75470 -396.901600 -431.09670   \n",
      "11998 -402.48422 -265.44583 -222.53365 -252.51994 -354.065500 -435.74020   \n",
      "11999 -569.40330 -432.81006 -402.12128 -427.02840 -450.925200 -403.64014   \n",
      "\n",
      "          mfcc_6     mfcc_7     mfcc_8     mfcc_9  ...  mfcc_29942  \\\n",
      "0     -188.88948 -192.92793 -198.64996 -205.36676  ...         NaN   \n",
      "1     -127.48655 -147.36304 -173.15262 -206.36018  ...         NaN   \n",
      "2     -154.01764 -105.64315  -93.18479 -100.65769  ...         NaN   \n",
      "3     -368.38434 -366.10820 -369.49774 -371.48330  ...         NaN   \n",
      "4     -328.54266 -344.72568 -359.26860 -376.84415  ...         NaN   \n",
      "...          ...        ...        ...        ...  ...         ...   \n",
      "11995 -383.24716 -407.05880 -401.32803 -403.24730  ...         NaN   \n",
      "11996 -387.86462 -349.09890 -298.46173 -279.32150  ...         NaN   \n",
      "11997 -458.27768 -415.12700 -367.14423 -356.79040  ...         NaN   \n",
      "11998 -463.90630 -434.85425 -338.91168 -293.68906  ...         NaN   \n",
      "11999 -360.11590 -380.71494 -443.04926 -498.42990  ...         NaN   \n",
      "\n",
      "       mfcc_29943  mfcc_29944  mfcc_29945  mfcc_29946  mfcc_29947  mfcc_29948  \\\n",
      "0             NaN         NaN         NaN         NaN         NaN         NaN   \n",
      "1             NaN         NaN         NaN         NaN         NaN         NaN   \n",
      "2             NaN         NaN         NaN         NaN         NaN         NaN   \n",
      "3             NaN         NaN         NaN         NaN         NaN         NaN   \n",
      "4             NaN         NaN         NaN         NaN         NaN         NaN   \n",
      "...           ...         ...         ...         ...         ...         ...   \n",
      "11995         NaN         NaN         NaN         NaN         NaN         NaN   \n",
      "11996         NaN         NaN         NaN         NaN         NaN         NaN   \n",
      "11997         NaN         NaN         NaN         NaN         NaN         NaN   \n",
      "11998         NaN         NaN         NaN         NaN         NaN         NaN   \n",
      "11999         NaN         NaN         NaN         NaN         NaN         NaN   \n",
      "\n",
      "       mfcc_29949  mfcc_29950  mfcc_29951  \n",
      "0             NaN         NaN         NaN  \n",
      "1             NaN         NaN         NaN  \n",
      "2             NaN         NaN         NaN  \n",
      "3             NaN         NaN         NaN  \n",
      "4             NaN         NaN         NaN  \n",
      "...           ...         ...         ...  \n",
      "11995         NaN         NaN         NaN  \n",
      "11996         NaN         NaN         NaN  \n",
      "11997         NaN         NaN         NaN  \n",
      "11998         NaN         NaN         NaN  \n",
      "11999         NaN         NaN         NaN  \n",
      "\n",
      "[12000 rows x 29952 columns]\n"
     ]
    }
   ],
   "source": [
    "mfcc = pd.read_csv(BASE_PATH + \"id_mfcc_solo_ridotto.csv\")\n",
    "\n",
    "mfcc_np = np.array(mfcc, dtype=np.float32)\n",
    "index = 0\n",
    "for row in mfcc_np:\n",
    "    row_counter = 0\n",
    "    for i in range(len(row)):\n",
    "        if np.isnan(row[i]):\n",
    "            row[i] = row[row_counter]\n",
    "            row_counter+=1\n",
    "    index += 1\n",
    "    print(index)\n",
    "print(mfcc_np)\n",
    "\n",
    "pd.DataFrame(mfcc_np).to_csv(BASE_PATH + \"mfcc_filled_circular.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "vector quantization con kmeans"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 29952)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "mfcc = pd.read_csv(BASE_PATH + \"mfcc_filled_circular.csv\")\n",
    "\n",
    "mfcc_32 = np.array(mfcc, dtype= np.float32)\n",
    "mfcc_32 = np.delete(mfcc_32, 0, axis=1)\n",
    "\n",
    "mfcc_32 = mfcc_32[:200]\n",
    "\n",
    "print(mfcc_32.shape)\n",
    "\n",
    "X = mfcc_32.reshape((-1, 1))\n",
    "\n",
    "\n",
    "kmeans = KMeans(n_clusters=50)\n",
    "kmeans.fit(X)\n",
    "\n",
    "values = kmeans.cluster_centers_.squeeze()\n",
    "labels = kmeans.labels_\n",
    "\n",
    "matrix = np.array(labels)\n",
    "matrix = matrix.reshape(mfcc_32.shape)\n",
    "\n",
    "pd.DataFrame(matrix).to_csv(BASE_PATH + \"obs_for_hmm.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "test set & train set"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "observations = np.array(pd.read_csv(BASE_PATH + \"obs_for_hmm.csv\"))\n",
    "observations = np.delete(observations, 0, axis=1)\n",
    "\n",
    "index = 0\n",
    "train_set = []\n",
    "test_set = []\n",
    "for row in observations:\n",
    "    if 0 <= index <= 34:\n",
    "        train_set.append(row)\n",
    "        index+=1\n",
    "    elif index <= 38:\n",
    "        test_set.append(row)\n",
    "        index+=1\n",
    "    elif index == 39:\n",
    "        test_set.append(row)\n",
    "        index = 0\n",
    "\n",
    "test_set = np.array(test_set)\n",
    "train_set = np.array(train_set)\n",
    "\n",
    "\n",
    "pd.DataFrame(train_set).to_csv(BASE_PATH + \"train_set_hmm.csv\")\n",
    "pd.DataFrame(test_set).to_csv(BASE_PATH + \"test_set_hmm.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "train_set = np.array(pd.read_csv(BASE_PATH + \"train_set_hmm.csv\"))\n",
    "train_set = np.delete(train_set, 0, axis=1)\n",
    "\n",
    "test_set = np.array(pd.read_csv(BASE_PATH + \"train_set_hmm.csv\"))\n",
    "test_set = np.delete(train_set, 0, axis=1)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting a model with 1997999 free scalar parameters with only 1048320 data points will result in a degenerate solution.\n"
     ]
    }
   ],
   "source": [
    "index = 0\n",
    "samples = []\n",
    "model = []\n",
    "\n",
    "for i in range(5):\n",
    "    samples.append(train_set[index : index + 35])\n",
    "    model.append(hmm.MultinomialHMM(n_components=50))\n",
    "    model[i].fit(samples[i])\n",
    "    print(model[i].transmat_)\n",
    "    index += 35\n",
    "\n",
    "    print(\"fitted\" + str(index))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "Must be overridden in subclass",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNotImplementedError\u001B[0m                       Traceback (most recent call last)",
      "Input \u001B[0;32mIn [57]\u001B[0m, in \u001B[0;36m<cell line: 8>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     18\u001B[0m answers \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m     19\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m mod \u001B[38;5;129;01min\u001B[39;00m model:\n\u001B[0;32m---> 20\u001B[0m     answers\u001B[38;5;241m.\u001B[39mappend(\u001B[43mmod\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mscore\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[43mtester\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m     22\u001B[0m answ \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mmax\u001B[39m(answers)\n\u001B[1;32m     24\u001B[0m pred_label \u001B[38;5;241m=\u001B[39m answers\u001B[38;5;241m.\u001B[39mindex(answ)\n",
      "File \u001B[0;32m~/PycharmProjects/HMM_SR_project/venv/lib/python3.10/site-packages/hmmlearn/base.py:259\u001B[0m, in \u001B[0;36mBaseHMM.score\u001B[0;34m(self, X, lengths)\u001B[0m\n\u001B[1;32m    236\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mscore\u001B[39m(\u001B[38;5;28mself\u001B[39m, X, lengths\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m    237\u001B[0m     \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    238\u001B[0m \u001B[38;5;124;03m    Compute the log probability under the model.\u001B[39;00m\n\u001B[1;32m    239\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    257\u001B[0m \u001B[38;5;124;03m    decode : Find most likely state sequence corresponding to ``X``.\u001B[39;00m\n\u001B[1;32m    258\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 259\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_score\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlengths\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcompute_posteriors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m[\u001B[38;5;241m0\u001B[39m]\n",
      "File \u001B[0;32m~/PycharmProjects/HMM_SR_project/venv/lib/python3.10/site-packages/hmmlearn/base.py:277\u001B[0m, in \u001B[0;36mBaseHMM._score\u001B[0;34m(self, X, lengths, compute_posteriors)\u001B[0m\n\u001B[1;32m    272\u001B[0m X \u001B[38;5;241m=\u001B[39m check_array(X)\n\u001B[1;32m    273\u001B[0m impl \u001B[38;5;241m=\u001B[39m {\n\u001B[1;32m    274\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mscaling\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_score_scaling,\n\u001B[1;32m    275\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlog\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_score_log,\n\u001B[1;32m    276\u001B[0m }[\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mimplementation]\n\u001B[0;32m--> 277\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mimpl\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    278\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlengths\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlengths\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcompute_posteriors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcompute_posteriors\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/HMM_SR_project/venv/lib/python3.10/site-packages/hmmlearn/base.py:289\u001B[0m, in \u001B[0;36mBaseHMM._score_log\u001B[0;34m(self, X, lengths, compute_posteriors)\u001B[0m\n\u001B[1;32m    287\u001B[0m sub_posteriors \u001B[38;5;241m=\u001B[39m [np\u001B[38;5;241m.\u001B[39mempty((\u001B[38;5;241m0\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_components))]\n\u001B[1;32m    288\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m sub_X \u001B[38;5;129;01min\u001B[39;00m _utils\u001B[38;5;241m.\u001B[39msplit_X_lengths(X, lengths):\n\u001B[0;32m--> 289\u001B[0m     log_frameprob \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_compute_log_likelihood\u001B[49m\u001B[43m(\u001B[49m\u001B[43msub_X\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    290\u001B[0m     log_probij, fwdlattice \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_do_forward_log_pass(log_frameprob)\n\u001B[1;32m    291\u001B[0m     log_prob \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m log_probij\n",
      "File \u001B[0;32m~/PycharmProjects/HMM_SR_project/venv/lib/python3.10/site-packages/hmmlearn/base.py:710\u001B[0m, in \u001B[0;36mBaseHMM._compute_log_likelihood\u001B[0;34m(self, X)\u001B[0m\n\u001B[1;32m    708\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m np\u001B[38;5;241m.\u001B[39mlog(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compute_likelihood(X))\n\u001B[1;32m    709\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 710\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mNotImplementedError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMust be overridden in subclass\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[0;31mNotImplementedError\u001B[0m: Must be overridden in subclass"
     ]
    }
   ],
   "source": [
    "tester = test_set[0:25]\n",
    "correct_label = 0\n",
    "counted = 0\n",
    "corrected = 0\n",
    "\n",
    "\n",
    "\n",
    "for i in range(tester.shape[0]):\n",
    "\n",
    "    counted+=1\n",
    "\n",
    "    if 0 <= i <= 4: correct_label = 0\n",
    "    elif 5<= i <= 9: correct_label = 1\n",
    "    elif 10<= i <= 14: correct_label = 2\n",
    "    elif 15<= i <= 19: correct_label = 3\n",
    "    elif 20<= i <= 24: correct_label = 4\n",
    "\n",
    "    answers = []\n",
    "    for mod in model:\n",
    "        answers.append(mod.score([tester[i]]))\n",
    "\n",
    "    answ = max(answers)\n",
    "\n",
    "    pred_label = answers.index(answ)\n",
    "    if pred_label == correct_label: corrected+=1\n",
    "\n",
    "    #print(pred_label, \" \", correct_label, \" max:\", answ, \" score:\", answers)\n",
    "\n",
    "print(corrected/counted)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "viterbi\n"
     ]
    }
   ],
   "source": [
    "mod = hmm.MultinomialHMM(n_components=50, algorithm=)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ]
}